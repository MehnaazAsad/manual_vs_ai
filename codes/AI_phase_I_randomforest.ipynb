{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3079633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27199ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "cheaters = np.load('csgo_dataset/cheaters/cheaters.npy')\n",
    "legit = np.load('csgo_dataset/legit/legit.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "242caa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data\n",
    "X = np.vstack((cheaters, legit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41002957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels (the fifth feature of the last timestep of each engagement) one label per player-engagement combo\n",
    "y = X[:, :, -1, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbcbee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 30)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4e8ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove labels from features\n",
    "X = X[:, :, :, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54449881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 30, 192, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62c9dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X):\n",
    "    \"\"\"\n",
    "    Extract features from the engagement data\n",
    "    X shape: (192, 4) - single engagement\n",
    "    \"\"\"\n",
    "    # Mean of each variable over time\n",
    "    mean_features = np.mean(X, axis=0)\n",
    "    \n",
    "    # Standard deviation of each variable over time\n",
    "    std_features = np.std(X, axis=0)\n",
    "    \n",
    "    # Max absolute change in yaw and pitch\n",
    "    max_yaw_change = np.max(np.abs(np.diff(X[:, 0])))\n",
    "    max_pitch_change = np.max(np.abs(np.diff(X[:, 1])))\n",
    "    \n",
    "    return np.hstack([mean_features, std_features, max_yaw_change, max_pitch_change])\n",
    "\n",
    "# Process players\n",
    "n_players = X.shape[0]\n",
    "n_features_per_engagement = 10  # 4 means + 4 stds + 2 max changes\n",
    "X_features = np.zeros((n_players, 30 * n_features_per_engagement))\n",
    "\n",
    "# Extract features for each player's engagements\n",
    "for player in range(n_players):\n",
    "    player_features = []\n",
    "    for engagement in range(30):\n",
    "        # Process one engagement\n",
    "        engagement_features = extract_features(X[player, engagement])\n",
    "        player_features.extend(engagement_features)\n",
    "    X_features[player] = np.array(player_features)\n",
    "    \n",
    "# Take first label for each player (since they're all the same)\n",
    "y_player = y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f1e95bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes before CV split:\n",
      "X_features shape: (12000, 300)\n",
      "y shape: (12000,)\n",
      "Class distribution: (array([0., 1.], dtype=float32), array([11601,   399]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes before CV split:\")\n",
    "print(\"X_features shape:\", X_features.shape)\n",
    "print(\"y shape:\", y_player.shape)\n",
    "print(\"Class distribution:\", np.unique(y_player, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55d19284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b3366f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "Train set class distribution: (array([0., 1.], dtype=float32), array([9284,  316]))\n",
      "Validation set class distribution: (array([0., 1.], dtype=float32), array([2317,   83]))\n",
      "\n",
      "Fold 1 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      2317\n",
      "         1.0       0.22      0.02      0.04        83\n",
      "\n",
      "    accuracy                           0.96      2400\n",
      "   macro avg       0.59      0.51      0.51      2400\n",
      "weighted avg       0.94      0.96      0.95      2400\n",
      "\n",
      "\n",
      "Fold 2:\n",
      "Train set class distribution: (array([0., 1.], dtype=float32), array([9279,  321]))\n",
      "Validation set class distribution: (array([0., 1.], dtype=float32), array([2322,   78]))\n",
      "\n",
      "Fold 2 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      2322\n",
      "         1.0       0.45      0.06      0.11        78\n",
      "\n",
      "    accuracy                           0.97      2400\n",
      "   macro avg       0.71      0.53      0.55      2400\n",
      "weighted avg       0.95      0.97      0.95      2400\n",
      "\n",
      "\n",
      "Fold 3:\n",
      "Train set class distribution: (array([0., 1.], dtype=float32), array([9277,  323]))\n",
      "Validation set class distribution: (array([0., 1.], dtype=float32), array([2324,   76]))\n",
      "\n",
      "Fold 3 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      2324\n",
      "         1.0       0.29      0.03      0.05        76\n",
      "\n",
      "    accuracy                           0.97      2400\n",
      "   macro avg       0.63      0.51      0.52      2400\n",
      "weighted avg       0.95      0.97      0.95      2400\n",
      "\n",
      "\n",
      "Fold 4:\n",
      "Train set class distribution: (array([0., 1.], dtype=float32), array([9283,  317]))\n",
      "Validation set class distribution: (array([0., 1.], dtype=float32), array([2318,   82]))\n",
      "\n",
      "Fold 4 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      2318\n",
      "         1.0       0.33      0.01      0.02        82\n",
      "\n",
      "    accuracy                           0.97      2400\n",
      "   macro avg       0.65      0.51      0.50      2400\n",
      "weighted avg       0.94      0.97      0.95      2400\n",
      "\n",
      "\n",
      "Fold 5:\n",
      "Train set class distribution: (array([0., 1.], dtype=float32), array([9281,  319]))\n",
      "Validation set class distribution: (array([0., 1.], dtype=float32), array([2320,   80]))\n",
      "\n",
      "Fold 5 Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      2320\n",
      "         1.0       0.12      0.01      0.02        80\n",
      "\n",
      "    accuracy                           0.96      2400\n",
      "   macro avg       0.55      0.50      0.50      2400\n",
      "weighted avg       0.94      0.96      0.95      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_features, y_player, groups=np.arange(n_players))):\n",
    "    X_train, X_val = X_features[train_idx], X_features[val_idx]\n",
    "    y_train, y_val = y_player[train_idx], y_player[val_idx]\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1}:\")\n",
    "    print(f\"Train set class distribution: {np.unique(y_train, return_counts=True)}\")\n",
    "    print(f\"Validation set class distribution: {np.unique(y_val, return_counts=True)}\")\n",
    "    \n",
    "    # Fit and predict\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    y_pred = rf_pipeline.predict(X_val)\n",
    "    \n",
    "    # Get classification report\n",
    "    print(f\"\\nFold {fold + 1} Results:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    fold_reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df430c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Averaged metrics across all folds:\n",
      "Class 0.0 precision: 96.8 (+/- 0.1)\n",
      "Class 1.0 precision: 28.4 (+/- 11.0)\n",
      "Class 0.0 recall: 99.8 (+/- 0.1)\n",
      "Class 1.0 recall: 2.8 (+/- 1.9)\n",
      "Class 0.0 f1-score: 98.2 (+/- 0.1)\n",
      "Class 1.0 f1-score: 5.0 (+/- 3.3)\n",
      "Average accuracy: 96.5% (+/- 0.2%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average metrics across folds\n",
    "print(\"\\nAveraged metrics across all folds:\")\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "classes = ['0.0', '1.0']  # non-cheater and cheater\n",
    "\n",
    "for metric in metrics:\n",
    "    for cls in classes:\n",
    "        values = [fold[cls][metric] * 100 for fold in fold_reports]\n",
    "        mean_value = np.mean(values)\n",
    "        std_value = np.std(values)\n",
    "        print(f\"Class {cls} {metric}: {mean_value:.1f} (+/- {std_value:.1f})\")\n",
    "\n",
    "# Calculate average accuracy\n",
    "accuracies = [fold['accuracy'] * 100 for fold in fold_reports]\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print(f\"Average accuracy: {mean_accuracy:.1f}% (+/- {std_accuracy:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77f675c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most important features:\n",
      "Engagement 1, mean_2: 0.0131\n",
      "Engagement 16, mean_3: 0.0107\n",
      "Engagement 22, std_1: 0.0097\n",
      "Engagement 2, mean_3: 0.0096\n",
      "Engagement 4, std_3: 0.0086\n",
      "Engagement 25, std_4: 0.0084\n",
      "Engagement 16, std_3: 0.0083\n",
      "Engagement 23, std_1: 0.0083\n",
      "Engagement 7, std_1: 0.0079\n",
      "Engagement 10, mean_4: 0.0077\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from the last fold's model\n",
    "feature_importances = rf_pipeline.named_steps['rf'].feature_importances_\n",
    "top_n = 10\n",
    "top_indices = np.argsort(feature_importances)[-top_n:]\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "for idx in reversed(top_indices):\n",
    "    engagement_num = idx // n_features_per_engagement\n",
    "    feature_num = idx % n_features_per_engagement\n",
    "    feature_type = ['mean_1', 'mean_2', 'mean_3', 'mean_4', \n",
    "                   'std_1', 'std_2', 'std_3', 'std_4',\n",
    "                   'max_yaw_change', 'max_pitch_change'][feature_num]\n",
    "    print(f\"Engagement {engagement_num}, {feature_type}: {feature_importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a7154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
